N = length(predictions)
r2 = as.character(round(summary(model)$r.squared, 2))
adj_r2 = as.character(round(summary(model)$adj.r.squared, 2))
print(adj_r2) #Adjusted R-squared
print(as.character(round(sqrt(sum(resids2)/N), 2))) #RMSE
}
# Step 2 - predicting and evaluating the model on train data
predictions = predict(reg_mod1, newdata = train)
eval_metrics(reg_mod1, train, predictions, target = 'respect')
# Step 3 - predicting and evaluating the model on test data
predictions = predict(reg_mod1, newdata = test)
eval_metrics(reg_mod1, test, predictions, target = 'respect')
#### 2. Lasso Regression
lambdas <- 10^seq(2, -3, by = -.1)
eval_results <- function(true, predicted, df) {
SSE <- sum((predicted - true)^2)
SST <- sum((true - mean(true))^2)
R_square <- 1 - SSE / SST
RMSE = sqrt(SSE/nrow(df))
# Model performance metrics
data.frame(
RMSE = RMSE,
Rsquare = R_square
)
}
# Setting alpha = 1 implements lasso regression
lasso_reg <- cv.glmnet(X_train, y_train, alpha = 1, lambda = lambdas, standardize = TRUE, nfolds = 5)
plot(lasso_reg)
# Best
lambda_best <- lasso_reg$lambda.min
lambda_best
lasso_model <- glmnet(X_train, y_train, alpha = 1, lambda = lambda_best, standardize = TRUE)
predictions <- predict(lasso_model, s = lambda_best, newx = X_test)
mean((predictions - y_test )^2) # Calculate test MSE
eval_results(y_test, predictions, test)
grid = 10^seq(10, -2, length = 100)
out = glmnet(X_full, y_full, alpha = 1, lambda = grid) # Fit lasso model on full dataset
performance_accuracy(reg_mod1)
install.packages("performance")
library(performance)
performance_accuracy(reg_mod1)
performance_accuracy(reg_mod2)
performance_accuracy(reg_mod3)
performance_accuracy(reg_mod4)
install.packages("caret")
library(caret)
######### Automating the Analysis of Online Deliberation #############
library(peRspective)
library(tidyverse)
library(readr)
library(readxl)
library(xtable)
library(knitr)
library(kableExtra)
library(stargazer)
library(writexl)
library(psych)
library(gridExtra)
library(ggcorrplot)
library(glmnet)
library(performance)
library(caret)
comment_data <- read.csv( "data/final/comment_data_preprocessed.csv")
thread_data <- read.csv("data/final/thread_data_preprocessed.csv")
# Level of analysis: Threads
# Adding alternative measures for
# 1. Argumentation (length comments)
comment_data$arg_l_coms <- nchar(comment_data$text_c)
hist(comment_data$arg_l_coms)
mean(comment_data$arg_l_coms)
# 2. Reciprocity (N comments)
comment_data$rec_n_coms <- comment_data$n_comments_sub
hist(comment_data$rec_n_coms)
mean(comment_data$rec_n_coms)
# 3. Respect (Toxicity) using Perspective API (Google)
# https://github.com/favstats/peRspective
#usethis::edit_r_environ()
# add:  perspective_api_key="key"
#test
#prsp_score(comment_data$text_c[1], languages = "en",
#           score_model = "TOXICITY", doNotStore = TRUE)
#big run
#tox_data <- comment_data%>%
#  prsp_stream(text = text_c,
#              text_id = id_c,
#              score_model = c("TOXICITY", "SEVERE_TOXICITY"),
#              safe_output = T,
#              languages = "en",
#              doNotStore = TRUE)
#
#write_xlsx(tox_data, "data/temp/tox_data.xlsx")
tox_data <- read_excel("data/temp/tox_data.xlsx")
tox_data$id_c <- tox_data$text_id
comment_data_tox <- left_join(comment_data, tox_data, by.y = "id_c")
hist(comment_data_tox$TOXICITY)
comment_data_tox%>%
arrange(desc(TOXICITY))%>%
select(text_c)%>%
head() # pretty accurate haha
# add scores to thread data
thread_data_tox <- comment_data_tox%>%
dplyr::group_by(id_sub) %>%
mutate(TOXICITY = mean(TOXICITY),
arg_l_coms = mean(arg_l_coms),
rec_n_coms = mean(rec_n_coms))%>%
slice(1)
#write.csv(comment_data_tox, file = "data/final/comment_data_tox.csv")
#write.csv(thread_data_tox, file = "data/final/thread_data_tox.csv")
############## PLOTS ############################################################
##### Correlation Plot with all qualitative and computational measures
corr_data <- comment_data%>%
dplyr::select(del_complexity_G, gonzalez_width, max_thread_depth, arg_l_coms, rec_n_coms, TOXICITY,
respect, argumentation, reciprocity, empathy, emotion, humor)%>%
mutate_all(~as.numeric(as.character(.)))%>%
plyr::rename(c("del_complexity_G" = "Structural Complexity",
"gonzalez_width" = "Thread Width",
"max_thread_depth" = "Thread Depth",
"arg_l_coms" = "Comment Length",
"rec_n_coms" = "Number of Replies",
"TOXICITY" = "Toxicity",
"respect" = "Respect",
"argumentation" = "Argumentation",
"reciprocity"  = "Reciprocity",
"empathy" = "Empathy",
"emotion" = "Emotion",
"humor" = "Humor"
))
######### Automating the Analysis of Online Deliberation #############
library(peRspective)
library(tidyverse)
library(readr)
library(readxl)
library(xtable)
library(knitr)
library(kableExtra)
library(stargazer)
library(writexl)
library(psych)
library(gridExtra)
library(ggcorrplot)
library(glmnet)
library(performance)
library(caret)
comment_data <- read.csv( "data/final/comment_data_preprocessed.csv")
thread_data <- read.csv("data/final/thread_data_preprocessed.csv")
# Level of analysis: Threads
# Adding alternative measures for
# 1. Argumentation (length comments)
comment_data$arg_l_coms <- nchar(comment_data$text_c)
hist(comment_data$arg_l_coms)
mean(comment_data$arg_l_coms)
# 2. Reciprocity (N comments)
comment_data$rec_n_coms <- comment_data$n_comments_sub
hist(comment_data$rec_n_coms)
mean(comment_data$rec_n_coms)
# 3. Respect (Toxicity) using Perspective API (Google)
# https://github.com/favstats/peRspective
#usethis::edit_r_environ()
# add:  perspective_api_key="key"
#test
#prsp_score(comment_data$text_c[1], languages = "en",
#           score_model = "TOXICITY", doNotStore = TRUE)
#big run
#tox_data <- comment_data%>%
#  prsp_stream(text = text_c,
#              text_id = id_c,
#              score_model = c("TOXICITY", "SEVERE_TOXICITY"),
#              safe_output = T,
#              languages = "en",
#              doNotStore = TRUE)
#
#write_xlsx(tox_data, "data/temp/tox_data.xlsx")
tox_data <- read_excel("data/temp/tox_data.xlsx")
tox_data$id_c <- tox_data$text_id
comment_data_tox <- left_join(comment_data, tox_data, by.y = "id_c")
hist(comment_data_tox$TOXICITY)
comment_data_tox%>%
arrange(desc(TOXICITY))%>%
select(text_c)%>%
head() # pretty accurate haha
# add scores to thread data
thread_data_tox <- comment_data_tox%>%
dplyr::group_by(id_sub) %>%
mutate(TOXICITY = mean(TOXICITY),
arg_l_coms = mean(arg_l_coms),
rec_n_coms = mean(rec_n_coms))%>%
slice(1)
#write.csv(comment_data_tox, file = "data/final/comment_data_tox.csv")
#write.csv(thread_data_tox, file = "data/final/thread_data_tox.csv")
comment_data <- comment_data_tox
thread_data <- thread_data_tox
############## PLOTS ############################################################
##### Correlation Plot with all qualitative and computational measures
corr_data <- comment_data%>%
dplyr::select(del_complexity_G, gonzalez_width, max_thread_depth, arg_l_coms, rec_n_coms, TOXICITY,
respect, argumentation, reciprocity, empathy, emotion, humor)%>%
mutate_all(~as.numeric(as.character(.)))%>%
plyr::rename(c("del_complexity_G" = "Structural Complexity",
"gonzalez_width" = "Thread Width",
"max_thread_depth" = "Thread Depth",
"arg_l_coms" = "Comment Length",
"rec_n_coms" = "Number of Replies",
"TOXICITY" = "Toxicity",
"respect" = "Respect",
"argumentation" = "Argumentation",
"reciprocity"  = "Reciprocity",
"empathy" = "Empathy",
"emotion" = "Emotion",
"humor" = "Humor"
))
corr <- round(cor(corr_data, use = "pairwise.complete.obs"), 1)
p.mat <- cor_pmat(corr_data, use = "pairwise.complete.obs")
corr_c_plot <- ggcorrplot(corr, method = "circle", type = "upper",
outline.col = "white",
title = "Bivariate Correlations - Comment Level Data", insig = "blank",
tl.cex = 8,
tl.srt = 90,
lab = T, lab_size = 3, show.legend = F)
corr_c_plot
#ggsave("output/corr_comments_plot.pdf", width = 6, height = 5, dpi = 300, corr_c_plot)
### Scatterplots of method comparision
# create summary score of textual measures
comment_data <- comment_data%>% # change to "thread_data" and run code below for thread level data
mutate(text_deliberation = (TOXICITY+arg_l_coms+rec_n_coms)/3,
deliberation = scale(deliberation),
text_deliberation = scale(text_deliberation),
del_complexity_G = scale(del_complexity_G))
sum <- comment_data%>%
group_by(subreddit)%>%
summarise(mean_del = mean(deliberation),
se_del = sd(deliberation)/sqrt(n()),
mean_txt = mean(text_deliberation),
se_txt = sd(text_deliberation)/sqrt(n()),
mean_str = mean(del_complexity_G),
se_str = sd(del_complexity_G)/sqrt(n()),
n = n()
)
p1 <- ggplot(comment_data, aes(x=deliberation, y=text_deliberation, colour = subreddit)) +
geom_point(alpha = 0.1)+
#geom_point(data=thread_data, alpha = 0.3, size=5)+
geom_point(data = sum, aes(x=mean_del, y=mean_txt),size = 3)+
geom_errorbarh(data = sum, aes(x=mean_del, y=mean_txt,
xmax = mean_del+se_del, xmin = mean_del-se_del))+
geom_errorbar(data = sum, aes(x=mean_del, y=mean_txt,
ymax = mean_txt+se_txt,ymin = mean_txt-se_txt))+
geom_smooth(data = comment_data, method = lm,  size = 0.5, color = "black",alpha = 0.3)+
theme_bw()+
scale_colour_manual(values = c("blue", "red"))+
labs(colour ="Subreddit Mean",
x = "Deliberative quality (content coding)",
y = "Textual features of deliberative quality")+
theme(legend.position = c(.88,.9))+
ylim(-1, 3)
p1
#ggsave("output/scatter_science_text.png", width = 6, height = 5, dpi = 500, p1)
# run old plot again (using structural measures)
p2 <- ggplot(comment_data, aes(x=deliberation, y=del_complexity_G, colour = subreddit)) +
geom_point(alpha = 0.1)+
#geom_point(data=thread_data, alpha = 0.3, size=5)+
geom_point(data = sum, aes(x=mean_del, y=mean_str), size = 3)+
geom_errorbarh(data = sum, aes(x=mean_del, y=mean_str,
xmax = mean_del+se_del, xmin = mean_del-se_del))+
geom_errorbar(data = sum, aes(x=mean_del, y=mean_str,
ymax = mean_str+se_str,ymin = mean_str-se_str))+
geom_smooth(data = comment_data, method = lm,  size = 0.5, color = "black",alpha = 0.3)+
theme_bw()+
scale_colour_manual(values = c("blue", "red"))+
labs(colour ="Subreddit Mean",
x = "Deliberative quality (content coding)",
y = "Structural complexity (depth x max width)")+
theme(legend.position = c(.88,.9))+
ylim(-1, 3)
p2
#ggsave("output/scatter_science_del.png", width = 6, height = 5, dpi = 500, p2)
combi <- grid.arrange(p2, p1, nrow = 1)
#ggsave("output/scatter_science_combi.png", width = 12, height = 5, dpi = 500, combi)
## lasso models
scale_vars <- function(x, na.rm = FALSE){
(x - mean(x, na.rm = na.rm)) / sd(x, na.rm)
}
ml_data <- comment_data%>%
dplyr::select(max_thread_depth, gonzalez_width, arg_l_coms, TOXICITY, rec_n_coms ,opposing,
deliberation, reciprocity, emotion, empathy, respect, argumentation)%>%
mutate(across(where(is.numeric), ~ scale_vars(.x, na.rm = TRUE)))
ml_data_t <- thread_data%>%
dplyr::select(max_thread_depth, gonzalez_width, arg_l_coms, TOXICITY, rec_n_coms ,opposing,
deliberation, reciprocity, emotion, empathy, respect, argumentation)%>%
mutate(across(where(is.numeric), ~ scale_vars(.x, na.rm = TRUE)))
reg_mod1 <- lm(respect ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data)
reg_mod2 <- lm(reciprocity ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data)
reg_mod3 <- lm(argumentation ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data)
reg_mod4 <- lm(deliberation ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data)
# thread level data
reg_mod5 <- lm(respect ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data_t)
ml_data <- comment_data%>%
dplyr::select(max_thread_depth, gonzalez_width, arg_l_coms, TOXICITY, rec_n_coms ,opposing,
deliberation, reciprocity, emotion, empathy, respect, argumentation)%>%
mutate(across(where(is.numeric), ~ scale_vars(.x, na.rm = TRUE)))
ml_data_t <- thread_data%>%
dplyr::select(max_thread_depth, gonzalez_width, arg_l_coms, TOXICITY, rec_n_coms ,opposing,
deliberation, reciprocity, emotion, empathy, respect, argumentation)%>%
mutate(across(where(is.numeric), ~ scale_vars(.x, na.rm = TRUE)))
# linear regression models
# comment level data
reg_mod1 <- lm(respect ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data)
reg_mod2 <- lm(reciprocity ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data)
reg_mod3 <- lm(argumentation ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data)
reg_mod4 <- lm(deliberation ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data)
# thread level data
reg_mod5 <- lm(respect ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data_t)
reg_mod6 <- lm(reciprocity ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data_t)
reg_mod7 <- lm(argumentation ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data_t)
reg_mod8 <- lm(deliberation ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data_t)
View(thread_data)
thread_data <- read.csv("data/final/thread_data_tox.csv")
## scaling variables
scale_vars <- function(x, na.rm = FALSE){
(x - mean(x, na.rm = na.rm)) / sd(x, na.rm)
}
ml_data <- comment_data%>%
dplyr::select(max_thread_depth, gonzalez_width, arg_l_coms, TOXICITY, rec_n_coms ,opposing,
deliberation, reciprocity, emotion, empathy, respect, argumentation)%>%
mutate(across(where(is.numeric), ~ scale_vars(.x, na.rm = TRUE)))
ml_data_t <- thread_data%>%
dplyr::select(max_thread_depth, gonzalez_width, arg_l_coms, TOXICITY, rec_n_coms ,opposing,
deliberation, reciprocity, emotion, empathy, respect, argumentation)%>%
mutate(across(where(is.numeric), ~ scale_vars(.x, na.rm = TRUE)))
# linear regression models
# comment level data
reg_mod1 <- lm(respect ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data)
reg_mod2 <- lm(reciprocity ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data)
reg_mod3 <- lm(argumentation ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data)
reg_mod4 <- lm(deliberation ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data)
# thread level data
reg_mod5 <- lm(respect ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data_t)
reg_mod6 <- lm(reciprocity ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data_t)
reg_mod7 <- lm(argumentation ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data_t)
reg_mod8 <- lm(deliberation ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data_t)
# comment level data
stargazer(reg_mod1, reg_mod2, reg_mod3, reg_mod4, type = "html", omit = "Constant", out = "table1.html")
#thread level data
stargazer(reg_mod5, reg_mod6, reg_mod7, reg_mod8, type = "html", omit = "Constant", out = "table2.html")
# linear regression models
# comment level data
reg_mod1 <- lm(respect ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data)
reg_mod2 <- lm(reciprocity ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data)
reg_mod3 <- lm(argumentation ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data)
reg_mod4 <- lm(deliberation ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data)
# thread level data
reg_mod5 <- lm(respect ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data_t)
reg_mod6 <- lm(reciprocity ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data_t)
reg_mod7 <- lm(argumentation ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data_t)
reg_mod8 <- lm(deliberation ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data_t)
# comment level data
stargazer(reg_mod1, reg_mod2, reg_mod3, reg_mod4, type = "html", omit = "Constant", out = "table1.html")
#thread level data
stargazer(reg_mod5, reg_mod6, reg_mod7, reg_mod8, type = "html", omit = "Constant", out = "table2.html")
performance_accuracy(reg_mod1)
# thread level data
reg_mod5 <- lm_robust(respect ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data_t)
library(estimatr)
# thread level data
reg_mod5 <- lm_robust(respect ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data_t)
#thread level data
stargazer(reg_mod5, reg_mod6, reg_mod7, reg_mod8, type = "html", omit = "Constant", out = "table2.html")
library(texreg)
reg_mod1 <- lm_robust(respect ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data)
reg_mod2 <- lm_robust(reciprocity ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data)
reg_mod3 <- lm_robust(argumentation ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data)
reg_mod4 <- lm_robust(deliberation ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data)
# thread level data
reg_mod5 <- lm_robust(respect ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data_t)
reg_mod6 <- lm_robust(reciprocity ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data_t)
reg_mod7 <- lm_robust(argumentation ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data_t)
reg_mod8 <- lm_robust(deliberation ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data_t)
texreg(list(reg_mod1, reg_mod2, reg_mod3, reg_mod4), include.ci = FALSE, single.row = TRUE,
#custom.coef.names=c('Intercept', '' ),
custom.model.names = c("Toxicity","Toxicity lasso","Length","Length lasso"))
knitreg(list(reg_mod1, reg_mod2, reg_mod3, reg_mod4), include.ci = FALSE, single.row = TRUE,
#custom.coef.names=c('Intercept', '' ),
custom.model.names = c("Toxicity","Toxicity lasso","Length","Length lasso"))
texreg(list(reg_mod1, reg_mod2, reg_mod3, reg_mod4), include.ci = FALSE, single.row = TRUE,
custom.coef.names=c('Intercept', 'Thread width', 'Thread depth', 'Comment length',
'Toxicity', 'Number of Comments', 'Opposing'),
custom.model.names = c("Respect","Reciprocity","Argumentation","Deliberation"))
knitreg(list(reg_mod1, reg_mod2, reg_mod3, reg_mod4), include.ci = FALSE, single.row = TRUE,
custom.coef.names=c('Intercept', 'Thread width', 'Thread depth', 'Comment length',
'Toxicity', 'Number of Comments', 'Opposing'),
custom.model.names = c("Respect","Reciprocity","Argumentation","Deliberation"))
texreg(list(reg_mod1, reg_mod2, reg_mod3, reg_mod4), include.ci = FALSE, single.row = TRUE,
custom.coef.names=c('Intercept', 'Thread width', 'Thread depth', 'Comment length',
'Toxicity', 'Number of Comments', 'Opposing'),
custom.model.names = c("Respect","Reciprocity","Argumentation","Deliberation"),
caption = "Comment level data")
knitreg(list(reg_mod1, reg_mod2, reg_mod3, reg_mod4), include.ci = FALSE, single.row = TRUE,
custom.coef.names=c('Intercept', 'Thread width', 'Thread depth', 'Comment length',
'Toxicity', 'Number of Comments', 'Opposing'),
custom.model.names = c("Respect","Reciprocity","Argumentation","Deliberation"),
caption = "Comment level data")
texreg(list(reg_mod5, reg_mod6, reg_mod7, reg_mod8), include.ci = FALSE, single.row = TRUE,
custom.coef.names=c('Intercept', 'Thread width', 'Thread depth', 'Comment length',
'Toxicity', 'Number of Comments', 'Opposing'),
custom.model.names = c("Respect","Reciprocity","Argumentation","Deliberation"),
caption = "Thread level data")
knitreg(list(reg_mod5, reg_mod6, reg_mod7, reg_mod8), include.ci = FALSE, single.row = TRUE,
custom.coef.names=c('Intercept', 'Thread width', 'Thread depth', 'Comment length',
'Toxicity', 'Number of Comments', 'Opposing'),
custom.model.names = c("Respect","Reciprocity","Argumentation","Deliberation"),
caption = "Thread level data")
knitreg(list(reg_mod5, reg_mod6, reg_mod7, reg_mod8), include.ci = FALSE, single.row = TRUE,
custom.coef.names=c('Intercept', 'Thread width', 'Thread depth', 'Comment length',
'Toxicity', 'Number of Comments', 'Opposing'),
#custom.model.names = c("Respect","Reciprocity","Argumentation","Deliberation"),
caption = "Thread level data")
reg_mod5 <- lm_robust(respect ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data_t)
reg_mod6 <- lm_robust(reciprocity ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data_t)
reg_mod7 <- lm_robust(argumentation ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data_t)
reg_mod8 <- lm_robust(deliberation ~ max_thread_depth + gonzalez_width + arg_l_coms + TOXICITY + rec_n_coms + opposing, data = ml_data_t)
knitreg(list(reg_mod5, reg_mod6, reg_mod7, reg_mod8), include.ci = FALSE, single.row = TRUE,
custom.coef.names=c('Intercept', 'Thread width', 'Thread depth', 'Comment length',
'Toxicity', 'Number of Comments', 'Opposing'),
#custom.model.names = c("Respect","Reciprocity","Argumentation","Deliberation"),
caption = "Thread level data")
knitreg(list(reg_mod1, reg_mod2, reg_mod3, reg_mod4), include.ci = FALSE, single.row = TRUE,
custom.coef.names=c('Intercept', 'Thread width', 'Thread depth', 'Comment length',
'Toxicity', 'Number of Comments', 'Opposing'),
custom.model.names = c("Respect","Reciprocity","Argumentation","Deliberation"),
caption = "Comment level data")
knitreg(list(reg_mod5, reg_mod6, reg_mod7, reg_mod8), include.ci = FALSE, single.row = TRUE,
custom.coef.names=c('Intercept', 'Thread width', 'Thread depth', 'Comment length',
'Toxicity', 'Number of Comments', 'Opposing'),
#custom.model.names = c("Respect","Reciprocity","Argumentation","Deliberation"),
caption = "Thread level data")
# train / test split
train_data <- ml_data %>% sample_frac(.80)
test_data <- ml_data %>% sample_frac(.20)
X_full <- ml_data %>% dplyr::select(-respect, -reciprocity, -argumentation, -deliberation)
X_train <- train_data %>% dplyr::select(-respect, -reciprocity, -argumentation, -deliberation)
X_test <- test_data %>% dplyr::select(-respect, -reciprocity, -argumentation, -deliberation)
# respect
y_full_resp <- ml_data$respect
y_train_resp <- train_data$respect
y_test_resp <- train_data$respect
# reciprocity
y_full_reci <- ml_data$reciprocity
y_train_reci <- train_data$reciprocity
y_test_reci <- train_data$reciprocity
# argumentation
y_full_arg <- ml_data$argumentation
y_train_arg <- train_data$argumentation
y_test_arg <- train_data$argumentation
# deliberation
y_full_del <- ml_data$deliberation
y_train_del <- train_data$deliberation
y_test_del <- train_data$deliberation
# define lambda grid for lasso model
grid = 10^seq(10, -2, length = 100)
# fit lasso model to training data
lasso_mod <- glmnet(X_train, y_train_resp, alpha=1, lambda = grid)
plot(lasso_mod)
# select best lambda value
set.seed(1)
cv.out = cv.glmnet(data.matrix(X_train), y_train_resp, alpha = 1)
# select best lambda value
set.seed(1)
cv.out = cv.glmnet(data.matrix(X_train), y_train_resp, alpha = 1)
plot(cv.out) # Draw plot of training MSE as a function of lambda
bestlam = cv.out$lambda.min # Select lamda that minimizes training MSE
lasso_pred = predict(lasso_mod, s = bestlam, newx = data.matrix(X_test)) # Use best lambda to predict test data
mean((lasso_pred - y_test_resp )^2) # Calculate test MSE
X_test <- test_data %>% dplyr::select(-respect, -reciprocity, -argumentation, -deliberation)
# train / test split
train_data <- ml_data %>% sample_frac(.80)
test_data <- ml_data %>% sample_frac(.20)
X_full <- ml_data %>% dplyr::select(-respect, -reciprocity, -argumentation, -deliberation)
X_train <- train_data %>% dplyr::select(-respect, -reciprocity, -argumentation, -deliberation)
X_test <- test_data %>% dplyr::select(-respect, -reciprocity, -argumentation, -deliberation)
# respect
y_full_resp <- ml_data$respect
y_full_resp <- ml_data$respect
y_train_resp <- train_data$respect
y_test_resp <- test_data$respect
# reciprocity
y_full_reci <- ml_data$reciprocity
y_train_reci <- train_data$reciprocity
y_test_reci <- test_data$reciprocity
# argumentation
y_full_arg <- ml_data$argumentation
y_train_arg <- train_data$argumentation
y_test_arg <- test_data$argumentation
# deliberation
y_full_del <- ml_data$deliberation
y_train_del <- train_data$deliberation
y_test_del <- test_data$deliberation
# define lambda grid for lasso model
grid = 10^seq(10, -2, length = 100)
# fit lasso model to training data
lasso_mod <- glmnet(X_train, y_train_resp, alpha=1, lambda = grid)
plot(lasso_mod)
# select best lambda value
set.seed(1)
cv.out = cv.glmnet(data.matrix(X_train), y_train_resp, alpha = 1)
plot(cv.out) # Draw plot of training MSE as a function of lambda
bestlam = cv.out$lambda.min # Select lamda that minimizes training MSE
lasso_pred = predict(lasso_mod, s = bestlam, newx = data.matrix(X_test)) # Use best lambda to predict test data
mean((lasso_pred - y_test_resp )^2) # Calculate test MSE
out = glmnet(X_full, y_full_resp, alpha = 1, lambda = grid) # Fit lasso model on full dataset
lasso_coef = predict(out, type = "coefficients", s = bestlam)[1:20,] # Display coefficients using lambda chosen by CV
lasso_coef
lasso_coef = predict(out, type = "coefficients", s = bestlam)[1:9,] # Display coefficients using lambda chosen by CV
lasso_coef
lasso_coef[lasso_coef != 0] # Display only non-zero coefficients
