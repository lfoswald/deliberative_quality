sd=my.sd,
se=my.se)
my.df%>%
xtable()%>%
kable()%>%
kable_styling(bootstrap_options = "striped",
full_width = FALSE,
position = "center")
p2 <- ggplot(my.df, aes(x=groups, y=mean)) +
geom_bar(stat="identity", aes(x=groups, y=mean),size=0.1,
width = 0.6, fill=c("steelblue1"), alpha = 0.7) +
theme_bw()+
theme(
axis.text.x = element_text(colour="black", size =12),
axis.text.y = element_text(colour="black", size =10),
axis.title.x = element_text( colour="black", size=12),
axis.title.y = element_text( colour="black", size=12))+
labs(x="",y="Deliberative structure (max width)", title="Thread level data")+
geom_errorbar(aes(ymin = mean-my.se, ymax = mean+my.se), width=.1)
p_str <- grid.arrange(p1, p2, nrow = 1)
ggsave("output/str_bars_G.png", dpi = 300, p_str)
# thread level data + grouped for subreddits
df <- thread_data %>%
dplyr::group_by(subreddit, wave, opposing)%>%
dplyr::summarise(se = sd(del_complexity_G)/sqrt(length(del_complexity_G)),
mean = mean(del_complexity_G))
df%>%
xtable()%>%
kable()%>%
kable_styling(bootstrap_options = "striped",
full_width = FALSE,
position = "center")
ggplot(df, aes(x=opposing, y=mean, fill = subreddit)) +
geom_bar(position=position_dodge(), stat="identity", colour='white', alpha = 0.7) +
geom_errorbar(aes(ymin=mean-se, ymax=mean+se), width=.1,position=position_dodge(.9),alpha = 0.7)+
theme_bw()+
scale_fill_manual(values=c("steelblue3", "steelblue1"))+
labs(x="Opposing submission content",y="Deliberative structure (max width)", title="Thread level data")+
facet_grid(vars(wave))
# total figure
p_total <- grid.arrange(p_qual, p_str, ncol = 1)
ggsave("output/total_bars.png", dpi = 300, p_total)
#### Structure vs. Quality ####
mod1 <- lm(deliberation ~ del_complexity_G, data = data)
mod2 <- lm(deliberation ~ del_complexity, data = data)
mod3 <- lm(deliberation ~ del_complexity_G, data = thread_data)
mod4 <- lm(deliberation ~ del_complexity, data = thread_data)
stargazer(mod1, mod2, mod3, mod4, type = "text", omit = "Constant")
mod5 <- lm(scale(del_complexity)   ~ scale(argumentation) + scale(respect) + scale(reciprocity) + scale(empathy) + scale(emotion) + scale(humor), data = data)
mod6 <- lm(scale(del_complexity_G) ~ scale(argumentation) + scale(respect) + scale(reciprocity) + scale(empathy) + scale(emotion) + scale(humor), data = data)
mod7 <- lm(scale(del_complexity)   ~ scale(argumentation) + scale(respect) + scale(reciprocity) + scale(empathy) + scale(emotion) + scale(humor), data = thread_data)
mod8 <- lm(scale(del_complexity_G) ~ scale(argumentation) + scale(respect) + scale(reciprocity) + scale(empathy) + scale(emotion) + scale(humor), data = thread_data)
stargazer(mod5, mod6, mod7, mod8, type = "text", omit = "Constant")
pa <- ggplot(data, aes(y=deliberation, x=log(del_structure))) +
geom_point(colour="seagreen3")+
geom_smooth( color = "grey")+
theme_bw(base_size = 8)+
ylab("Deliberative Quality (Content Coding)")+
xlab("Structural Complexity (Network Metrics, In-Degrees)")
pb <- ggplot(data, aes(y=deliberation, x=log(del_complexity))) +
geom_point(color="seagreen3")+
geom_smooth(color = "grey")+
theme_bw(base_size = 8)+
ylab("")+
xlab("Structural Complexity (Network Metrics, Users)")
pc <- ggplot(data, aes(y=deliberation, x=log(del_complexity_G))) +
geom_point(colour="seagreen3")+
geom_smooth(color = "grey")+
theme_bw(base_size = 8)+
ylab("")+
xlab("Structural Complexity (Network Metrics, Gonzalez)")
p_pred <- grid.arrange(pa, pb, pc, nrow = 1)
ggsave("output/qual_str_prediction.png", width = 10, height = 3 ,dpi = 600, p_pred)
####  Scientific consensus and deliberation ####
m1 <- lm(scale(deliberation) ~ subreddit + opposing + opposing * subreddit, data = thread_data)
m2 <- lm(scale(del_complexity_G) ~ subreddit + opposing + opposing * subreddit, data = thread_data)
m3 <- lm(scale(del_complexity) ~ subreddit + opposing + opposing * subreddit, data = thread_data)
stargazer(m1,m2,m3, type = "text", omit = "Constant")
m5 <- lm(scale(deliberation) ~ subreddit + opposing + opposing * subreddit, data = data)
m6 <- lm(scale(del_complexity_G) ~ subreddit + opposing + opposing * subreddit, data = data)
m7 <- lm(scale(del_complexity) ~ subreddit + opposing + opposing * subreddit, data = data)
stargazer(m5,m6,m7, type = "text", omit = "Constant")
ggplot(data, aes(x=scale(deliberation), y=scale(del_complexity_G), colour = subreddit)) +
geom_point(alpha = 0.1)+
#geom_point(data=thread_data, alpha = 0.3, size=5)+
geom_point(data=data %>%
group_by(subreddit) %>%
summarise_at(vars("deliberation","del_complexity_G"), mean),
size=4, shape=23, fill = "black",stroke = 1.5)+
geom_smooth(data = data,  size = 0.5, color = "black",alpha = 0.3)+
theme_bw()+
scale_colour_manual(values = c("#fb9a99", "#1f78b4"))+
labs(colour ="Subreddit Mean",
x = "Deliberative quality (content coding)",
y = "Structural complexity (depth x max width)")+
theme(legend.position = c(.88,.9))
ggsave("output/scatter_science_del.png", width = 6, height = 5, dpi = 500)
#### Depth x Max Width scatters  ####
q <- ggplot(thread_data, aes(max_thread_depth, gonzalez_width))+
geom_point(aes(colour = as.factor(opposing), size = n_comments_sub),
position = position_jitter(width = 2, height = 0),
alpha = 0.5)+
theme_bw()+
facet_grid(vars(wave), vars(subreddit))+
xlab("Depth")+
ylab("Max Width")+
scale_colour_manual(name="Submission Content",
labels=c("congruent", "opposing"),
values=c("#1f78b4","#fb9a99")) +
scale_size_continuous(name="Number of Comments")
ggsave(file="output/G_width_depth.pdf",width = 8, height = 6, dpi = 500, q)
#### Sarcasm between Subreddits #####
options(digits = 2)
means <- data %>%
group_by(subreddit)%>%
summarize(sarcasm = mean(civ_sar),
paternalism = mean(civ_pat),
comments = n())
sds <- data %>%
group_by(subreddit)%>%
summarize(sarcasm = sd(civ_sar),
paternalism = sd(civ_pat),
comments = n())
vars <- list(civ_sar, civ_pat)
var_names <- c("sarcasm","paternalism")
t <- c()
t_p <- c()
df <- c()
for(var in vars){
test = t.test(var ~ subreddit, data = data)
t = c(t, test$statistic)
df = c(df, test$parameter)
t_p = c(t_p, round(test$p.value,3))
}
ts <- data.frame(var_names, t,df, t_p)
ts[nrow(ts)+1,] <- NA
ts.T <- t(ts[,2:ncol(ts)])
colnames(ts.T) <- ts[,1]
ts <- tibble::rownames_to_column(data.frame(ts.T), "stat")
colnames(ts) <- colnames(means)
rbind(means,sds,ts)%>%
xtable()%>%
kable()%>% #kable("latex")
kable_styling(bootstrap_options = "striped",
full_width = FALSE,
position = "center")
library(tidyverse)
library(readr)
library(readxl)
library(xtable)
library(knitr)
library(kableExtra)
library(stargazer)
library(writexl)
library(psych)
library(gridExtra)
comment_data <- read.csv( "data/final/comment_data_preprocessed.csv")
thread_data <- read.csv("data/final/thread_data_preprocessed.csv")
data <- comment_data
my.mean<-tapply(data[,"deliberation"],data[,"subreddit"],mean, na.rm =T)
my.sd<-tapply(data[,"deliberation"],data[,"subreddit"],sd)
my.nr<-as.vector(table(data[,"subreddit"]))
my.se<-my.sd/sqrt(my.nr)
my.df<-data.frame(groups=factor(names(my.mean),labels =c("climate change","climate skeptics")),
mean=my.mean,
sd=my.sd,
se=my.se)
my.df%>%
xtable()%>%
kable()%>%
kable_styling(bootstrap_options = "striped",
full_width = FALSE,
position = "center")
dim(comment_data)
my.mean<-tapply(thread_data[,"deliberation"],thread_data[,"subreddit"],mean, na.rm =T)
my.sd<-tapply(thread_data[,"deliberation"],thread_data[,"subreddit"],sd)
my.nr<-as.vector(table(thread_data[,"subreddit"]))
my.se<-my.sd/sqrt(my.nr)
my.df<-data.frame(groups=factor(names(my.mean),labels =c("climate change ","climate skeptic")),
mean=my.mean,
sd=my.sd,
se=my.se)
my.df%>%
xtable()%>%
kable()%>%
kable_styling(bootstrap_options = "striped",
full_width = FALSE,
position = "center")
dim(thread_data)
my.nr
library(tidyverse)
library(readr)
library(readxl)
library(xtable)
library(knitr)
library(kableExtra)
library(stargazer)
library(writexl)
library(psych)
library(gridExtra)
comment_data <- read.csv( "data/final/comment_data_preprocessed.csv")
thread_data <- read.csv("data/final/thread_data_preprocessed.csv")
# date range
comment_data%>%
group_by(wave)%>%
summarize(start = min(date),
end = max(date))
# comment in-degree range
comment_data%>%
group_by(subreddit)%>%
summarize(mean = min(in_degree_com),
max = max(in_degree_com))
# N comments
comment_data%>%
group_by(subreddit, wave)%>%
summarise(n())%>%
xtable()%>%
kable()%>%
kable_styling(bootstrap_options = "striped",
full_width = FALSE,
position = "center")
# N threads
thread_data%>%
group_by(subreddit, wave)%>%
summarise(n())%>%
xtable()%>%
kable()%>%
kable_styling(bootstrap_options = "striped",
full_width = FALSE,
position = "center")
# comment level data
data <- comment_data
my.mean<-tapply(data[,"deliberation"],data[,"subreddit"],mean, na.rm =T)
my.sd<-tapply(data[,"deliberation"],data[,"subreddit"],sd)
my.nr<-as.vector(table(data[,"subreddit"]))
my.se<-my.sd/sqrt(my.nr)
my.df<-data.frame(groups=factor(names(my.mean),labels =c("climate change","climate skeptics")),
mean=my.mean,
sd=my.sd,
se=my.se)
my.df%>%
xtable()%>%
kable()%>%
kable_styling(bootstrap_options = "striped",
full_width = FALSE,
position = "center")
p1 <- ggplot(my.df, aes(x=groups, y=mean)) +
geom_bar(stat="identity", aes(x=groups, y=mean),size=0.1,
width = 0.6, fill=c("seagreen3"), alpha = 0.7) +
theme_bw()+
theme(
axis.text.x = element_text(colour="black", size =12),
axis.text.y = element_text(colour="black", size =10),
axis.title.x = element_text( colour="black", size=12),
axis.title.y = element_text( colour="black", size=12))+
labs(x="",y="Deliberative quality",title="Comment level data")+
geom_errorbar(aes(ymin = mean-my.se, ymax = mean+my.se), width=.1)
# thread level data
my.mean<-tapply(thread_data[,"deliberation"],thread_data[,"subreddit"],mean, na.rm =T)
my.sd<-tapply(thread_data[,"deliberation"],thread_data[,"subreddit"],sd)
my.nr<-as.vector(table(thread_data[,"subreddit"]))
my.se<-my.sd/sqrt(my.nr)
my.df<-data.frame(groups=factor(names(my.mean),labels =c("climate change ","climate skeptic")),
mean=my.mean,
sd=my.sd,
se=my.se)
my.df%>%
xtable()%>%
kable()%>%
kable_styling(bootstrap_options = "striped",
full_width = FALSE,
position = "center")
p2 <- ggplot(my.df, aes(x=groups, y=mean)) +
geom_bar(stat="identity", aes(x=groups, y=mean),size=0.1,
width = 0.6, fill=c("seagreen2"), alpha = 0.7) +
theme_bw()+
theme(
axis.text.x = element_text(colour="black", size =12),
axis.text.y = element_text(colour="black", size =10),
axis.title.x = element_text( colour="black", size=12),
axis.title.y = element_text( colour="black", size=12))+
labs(x="",y="Deliberative quality", title="Thread level data")+
geom_errorbar(aes(ymin = mean-my.se, ymax = mean+my.se), width=.1)
p_qual <- grid.arrange(p1, p2, nrow = 1)
ggsave("output/del_qual_bars.png", dpi = 300, p_qual)
# thread level data + grouped for subreddits
df <- thread_data %>%
group_by(subreddit, wave, opposing)%>%
summarise(se = sd(deliberation)/sqrt(length(deliberation)),
mean = mean(deliberation))
ggplot(df, aes(x=opposing, y=mean, fill = subreddit)) +
geom_bar(position=position_dodge(), stat="identity", colour='white', alpha = 0.7) +
geom_errorbar(aes(ymin=mean-se, ymax=mean+se), width=.1,position=position_dodge(.9),alpha = 0.7)+
theme_bw()+
scale_fill_manual(values=c("seagreen3", "seagreen2"))+
labs(x="opposing submission content",y="deliberative quality of threads", title="Thread   level data")+
facet_grid(vars(wave))
# comment level data
my.mean<-tapply(data[,"del_complexity_G"],data[,"subreddit"],mean, na.rm =T)
my.sd<-tapply(data[,"del_complexity_G"],data[,"subreddit"],sd)
my.nr<-as.vector(table(data[,"subreddit"]))
my.se<-my.sd/sqrt(my.nr)
my.df<-data.frame(groups=factor(names(my.mean),labels =c("climate change","climate skeptics")),
mean=my.mean,
sd=my.sd,
se=my.se)
my.df%>%
xtable()%>%
kable()%>%
kable_styling(bootstrap_options = "striped",
full_width = FALSE,
position = "center")
p1 <- ggplot(my.df, aes(x=groups, y=mean)) +
geom_bar(stat="identity", aes(x=groups, y=mean),size=0.1,
width = 0.6, fill=c("steelblue3"), alpha = 0.7) +
theme_bw()+
theme(
axis.text.x = element_text(colour="black", size =12),
axis.text.y = element_text(colour="black", size =10),
axis.title.x = element_text( colour="black", size=12),
axis.title.y = element_text( colour="black", size=12))+
labs(x="",y="Deliberative structure (max width)",title="Comment level data")+
geom_errorbar(aes(ymin = mean-my.se, ymax = mean+my.se), width=.1)
# thread level data
my.mean<-tapply(thread_data[,"del_complexity_G"],thread_data[,"subreddit"],mean, na.rm =T)
my.sd<-tapply(thread_data[,"del_complexity_G"],thread_data[,"subreddit"],sd)
my.nr<-as.vector(table(thread_data[,"subreddit"]))
my.se<-my.sd/sqrt(my.nr)
my.df<-data.frame(groups=factor(names(my.mean),labels =c("climate change","climate skeptics")),
mean=my.mean,
sd=my.sd,
se=my.se)
my.df%>%
xtable()%>%
kable()%>%
kable_styling(bootstrap_options = "striped",
full_width = FALSE,
position = "center")
p2 <- ggplot(my.df, aes(x=groups, y=mean)) +
geom_bar(stat="identity", aes(x=groups, y=mean),size=0.1,
width = 0.6, fill=c("steelblue1"), alpha = 0.7) +
theme_bw()+
theme(
axis.text.x = element_text(colour="black", size =12),
axis.text.y = element_text(colour="black", size =10),
axis.title.x = element_text( colour="black", size=12),
axis.title.y = element_text( colour="black", size=12))+
labs(x="",y="Deliberative structure (max width)", title="Thread level data")+
geom_errorbar(aes(ymin = mean-my.se, ymax = mean+my.se), width=.1)
p_str <- grid.arrange(p1, p2, nrow = 1)
ggsave("output/str_bars_G.png", dpi = 300, p_str)
# thread level data + grouped for subreddits
df <- thread_data %>%
dplyr::group_by(subreddit, wave, opposing)%>%
dplyr::summarise(se = sd(del_complexity_G)/sqrt(length(del_complexity_G)),
mean = mean(del_complexity_G))
df%>%
xtable()%>%
kable()%>%
kable_styling(bootstrap_options = "striped",
full_width = FALSE,
position = "center")
ggplot(df, aes(x=opposing, y=mean, fill = subreddit)) +
geom_bar(position=position_dodge(), stat="identity", colour='white', alpha = 0.7) +
geom_errorbar(aes(ymin=mean-se, ymax=mean+se), width=.1,position=position_dodge(.9),alpha = 0.7)+
theme_bw()+
scale_fill_manual(values=c("steelblue3", "steelblue1"))+
labs(x="Opposing submission content",y="Deliberative structure (max width)", title="Thread level data")+
facet_grid(vars(wave))
# total figure
p_total <- grid.arrange(p_qual, p_str, ncol = 1)
ggsave("output/total_bars.png", dpi = 300, p_total)
mod1 <- lm(deliberation ~ del_complexity_G, data = data)
mod2 <- lm(deliberation ~ del_complexity, data = data)
mod3 <- lm(deliberation ~ del_complexity_G, data = thread_data)
mod4 <- lm(deliberation ~ del_complexity, data = thread_data)
stargazer(mod1, mod2, mod3, mod4, type = "text", omit = "Constant")
mod5 <- lm(scale(del_complexity)   ~ scale(argumentation) + scale(respect) + scale(reciprocity) + scale(empathy) + scale(emotion) + scale(humor), data = data)
mod6 <- lm(scale(del_complexity_G) ~ scale(argumentation) + scale(respect) + scale(reciprocity) + scale(empathy) + scale(emotion) + scale(humor), data = data)
mod7 <- lm(scale(del_complexity)   ~ scale(argumentation) + scale(respect) + scale(reciprocity) + scale(empathy) + scale(emotion) + scale(humor), data = thread_data)
mod8 <- lm(scale(del_complexity_G) ~ scale(argumentation) + scale(respect) + scale(reciprocity) + scale(empathy) + scale(emotion) + scale(humor), data = thread_data)
stargazer(mod5, mod6, mod7, mod8, type = "text", omit = "Constant")
pa <- ggplot(data, aes(y=deliberation, x=log(del_structure))) +
geom_point(colour="seagreen3")+
geom_smooth( color = "grey")+
theme_bw(base_size = 8)+
ylab("Deliberative Quality (Content Coding)")+
xlab("Structural Complexity (Network Metrics, In-Degrees)")
pb <- ggplot(data, aes(y=deliberation, x=log(del_complexity))) +
geom_point(color="seagreen3")+
geom_smooth(color = "grey")+
theme_bw(base_size = 8)+
ylab("")+
xlab("Structural Complexity (Network Metrics, Users)")
pc <- ggplot(data, aes(y=deliberation, x=log(del_complexity_G))) +
geom_point(colour="seagreen3")+
geom_smooth(color = "grey")+
theme_bw(base_size = 8)+
ylab("")+
xlab("Structural Complexity (Network Metrics, Gonzalez)")
p_pred <- grid.arrange(pa, pb, pc, nrow = 1)
ggsave("output/qual_str_prediction.png", width = 10, height = 3 ,dpi = 600, p_pred)
m1 <- lm(scale(deliberation) ~ subreddit + opposing + opposing * subreddit, data = thread_data)
m2 <- lm(scale(del_complexity_G) ~ subreddit + opposing + opposing * subreddit, data = thread_data)
m3 <- lm(scale(del_complexity) ~ subreddit + opposing + opposing * subreddit, data = thread_data)
stargazer(m1,m2,m3, type = "text", omit = "Constant")
m5 <- lm(scale(deliberation) ~ subreddit + opposing + opposing * subreddit, data = data)
m6 <- lm(scale(del_complexity_G) ~ subreddit + opposing + opposing * subreddit, data = data)
m7 <- lm(scale(del_complexity) ~ subreddit + opposing + opposing * subreddit, data = data)
stargazer(m5,m6,m7, type = "text", omit = "Constant")
ggplot(data, aes(x=scale(deliberation), y=scale(del_complexity_G), colour = subreddit)) +
geom_point(alpha = 0.1)+
#geom_point(data=thread_data, alpha = 0.3, size=5)+
geom_point(data=data %>%
group_by(subreddit) %>%
summarise_at(vars("deliberation","del_complexity_G"), mean),
size=4, shape=23, fill = "black",stroke = 1.5)+
geom_smooth(data = data,  size = 0.5, color = "black",alpha = 0.3)+
theme_bw()+
scale_colour_manual(values = c("#fb9a99", "#1f78b4"))+
labs(colour ="Subreddit Mean",
x = "Deliberative quality (content coding)",
y = "Structural complexity (depth x max width)")+
theme(legend.position = c(.88,.9))
ggsave("output/scatter_science_del.png", width = 6, height = 5, dpi = 500)
#### Depth x Max Width scatters  ####
q <- ggplot(thread_data, aes(max_thread_depth, gonzalez_width))+
geom_point(aes(colour = as.factor(opposing), size = n_comments_sub),
position = position_jitter(width = 2, height = 0),
alpha = 0.5)+
theme_bw()+
facet_grid(vars(wave), vars(subreddit))+
xlab("Depth")+
ylab("Max Width")+
scale_colour_manual(name="Submission Content",
labels=c("congruent", "opposing"),
values=c("#1f78b4","#fb9a99")) +
scale_size_continuous(name="Number of Comments")
ggsave(file="output/G_width_depth.pdf",width = 8, height = 6, dpi = 500, q)
#### Sarcasm between Subreddits #####
options(digits = 2)
means <- data %>%
group_by(subreddit)%>%
summarize(sarcasm = mean(civ_sar),
paternalism = mean(civ_pat),
comments = n())
sds <- data %>%
group_by(subreddit)%>%
summarize(sarcasm = sd(civ_sar),
paternalism = sd(civ_pat),
comments = n())
vars <- list(civ_sar, civ_pat)
var_names <- c("sarcasm","paternalism")
t <- c()
t_p <- c()
df <- c()
for(var in vars){
test = t.test(var ~ subreddit, data = data)
t = c(t, test$statistic)
df = c(df, test$parameter)
t_p = c(t_p, round(test$p.value,3))
}
ts <- data.frame(var_names, t,df, t_p)
ts[nrow(ts)+1,] <- NA
ts.T <- t(ts[,2:ncol(ts)])
colnames(ts.T) <- ts[,1]
ts <- tibble::rownames_to_column(data.frame(ts.T), "stat")
colnames(ts) <- colnames(means)
rbind(means,sds,ts)%>%
xtable()%>%
kable()%>% #kable("latex")
kable_styling(bootstrap_options = "striped",
full_width = FALSE,
position = "center")
names(comment_data)
# 1. Argumentation (length comments)
data$arg_l_coms <-
comment_data$text_c
# 1. Argumentation (length comments)
data$arg_l_coms <-
comment_data$text_c[1]
comment_data$text_c[1]
devtools::install_github("favstats/peRspective")
#devtools::install_github("favstats/peRspective")
library(peRspective)
library(tidyverse)
comment_data <- read.csv( "data/final/comment_data_preprocessed.csv")
thread_data <- read.csv("data/final/thread_data_preprocessed.csv")
# 1. Argumentation (length comments)
comment_data$arg_l_coms <- nchar(comment_data$text_c)
mean(comment_data$arg_l_coms)
hist(comment_data$arg_l_coms)
# 2. Reciprocity (N comments)
comment_data$rec_n_coms <- comment_data$n_comments_sub
hist(comment_data$rec_n_coms)
mean(comment_data$rec_n_coms)
usethis::edit_r_environ()
my_text <- "You wrote this? Wow. This is dumb and childish, please go f**** yourself."
text_scores <- prsp_score(
text = my_text,
languages = "en",
score_model = peRspective::prsp_models
)
text_scores %>%
tidyr::gather() %>%
dplyr::mutate(key = forcats::fct_reorder(key, value)) %>%
ggplot2::ggplot(ggplot2::aes(key, value)) +
ggplot2::geom_col() +
ggplot2::coord_flip() +
ggplot2::ylim(0, 1) +
ggplot2::geom_hline(yintercept = 0.5, linetype = "dashed") +
ggplot2::labs(x = "Model", y = "Probability", title = "Perspective API Results")
