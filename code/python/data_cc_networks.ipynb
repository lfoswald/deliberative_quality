{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection - Wildfires & Climate Change "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- developer: name\n",
    "- personal-use-script: A\n",
    "- secret: ABC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "from datetime import datetime \n",
    "import networkx as nx \n",
    "import pickle\n",
    "import pydot\n",
    "from networkx.drawing.nx_pydot import graphviz_layout\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id='A',\n",
    "                     client_secret='ABC',\n",
    "                     user_agent='name',\n",
    "                     username= 'name', \n",
    "                     password= 'name'\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xxx delete before publishing xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id='u1l3H359SXM0pQ',\n",
    "                     client_secret='lq7ouUvkECW6ofAhNS9ai0ZJjJ0',\n",
    "                     user_agent='lfo_cs_sds20',\n",
    "                     username= 'lfo_cs_sds20', \n",
    "                     password= 'lfo_cs_sds20'\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_list = [\n",
    " 'AskScienceDiscussion',\n",
    " 'askscience',\n",
    " 'climatechange',\n",
    " 'climateskeptics'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment Dataframe for multiple Subreddits\n",
    "\n",
    "* Iterating through a list of subreddits\n",
    "* Iterating through unlimmited number of hot submissions that contain the keyword \"fire\" in each subreddit\n",
    "* Getting the comments for each submission\n",
    "* Saving the author (if not deleted)\n",
    "* Saving the comment body (if not deleted)\n",
    "* Append dataframe-list with comment id, body, author name, upvotes, timestamp, comment level (depth) and parent id and subreddit name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub in sub_list:\n",
    "    subreddit = reddit.subreddit(sub)\n",
    "    for c, submission in enumerate(subreddit.hot(limit=None)):\n",
    "        if \"fire\" in submission.title:\n",
    "            for c,comment in enumerate(submission.comments.list()):\n",
    "                # THe try exists because some reddit comments are from authors who \n",
    "                # have deleted their account, but the comments persist. \n",
    "                try:\n",
    "                    x = comment.author.name,\n",
    "                    authorname = x[0]\n",
    "                except AttributeError:\n",
    "                    authorname = \"[deleted]\"\n",
    "            \n",
    "                try:\n",
    "                    comment_body = comment.body,\n",
    "                except AttributeError:\n",
    "                    comment_body = \"[deleted]\"\n",
    "            \n",
    "                try: \n",
    "                    df_list.append([ \\\n",
    "                    comment.id,\n",
    "                    comment_body,\n",
    "                    authorname,\n",
    "                    comment.ups,\n",
    "                    comment.created_utc,\n",
    "                    comment.depth,\n",
    "                    comment.parent_id[3:],\n",
    "                    subreddit\n",
    "                    ])\n",
    "                except AttributeError:\n",
    "                    continue\n",
    "                    \n",
    "reddit_df = pd.DataFrame(df_list,columns=[\"id\",\"body\",\"authorname\",\"ups\",\"created_utc\",\"depth\",\"parent_id\",\"subreddit\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datetime object\n",
    "reddit_df[\"date\"] = reddit_df[\"created_utc\"].map(lambda x: datetime.utcfromtimestamp(x))\n",
    "\n",
    "display(reddit_df.head(10))\n",
    "reddit_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Did this in April 2020 for Australian Wildfires and in October 2020 for Californian Wildfires (With same keyword settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data (serialize)\n",
    "with open('fire_reddit_df.pickle', 'wb') as handle:\n",
    "    pickle.dump(reddit_df, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# also save datafrate as csv \n",
    "reddit_df.to_csv('fire_reddit_comments_df.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create comment tree (acyclic graph) for each subreddit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub in sub_list:\n",
    "    \n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    node_set = set([])\n",
    "    \n",
    "    subreddit = reddit.subreddit(sub)\n",
    "    \n",
    "    for submission in subreddit.hot(limit=None):\n",
    "        if \"fire\" in submission.title:\n",
    "            submission.comments.replace_more(limit=None)\n",
    "            \n",
    "            for i in submission.comments.list():\n",
    "                try:\n",
    "                    G.add_node(i.id, depth=i.depth,name=i.author.name)\n",
    "                except AttributeError: \n",
    "                    G.add_node(i.id, depth=i.depth,name=\"[Deleted]\")\n",
    "                node_set.add(i.id)\n",
    "            \n",
    "            for i in submission.comments.list():\n",
    "                if i.parent_id and i.parent_id[3:] in node_set:\n",
    "                    G.add_edge(i.id,i.parent_id[3:])\n",
    "    \n",
    "    print(subreddit,G.number_of_nodes(),'nodes')\n",
    "\n",
    "    nx.write_gexf(G,('%s.gexf'%subreddit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Australia and California Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: DeprecationWarning: The name modaction has been deprecated. Please import modaction as mod_action. This feature will be removed on the next major version release.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Load reddit_df for Australia and California as pickles\n",
    "with open('aus_fire_reddit_df.pickle', 'rb') as handle:\n",
    "    reddit_df_aus = pickle.load(handle)\n",
    "\n",
    "with open('cal_fire_reddit_df.pickle', 'rb') as handle:\n",
    "    reddit_df_cal = pickle.load(handle)\n",
    "\n",
    "\n",
    "reddit_df_aus['wave'] = 'australia'  \n",
    "reddit_df_cal['wave'] = 'california' \n",
    "        \n",
    "reddit_df = reddit_df_aus.append(reddit_df_cal)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data (serialize)\n",
    "with open('reddit_df.pickle', 'wb') as handle:\n",
    "    pickle.dump(reddit_df, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# save datafrate as csv \n",
    "reddit_df.to_csv('reddit_df.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find original submission to comment trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>body</th>\n",
       "      <th>authorname</th>\n",
       "      <th>ups</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>depth</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>date</th>\n",
       "      <th>wave</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fktjz0a</td>\n",
       "      <td>(Yep.   You could do this experiment now.   Li...</td>\n",
       "      <td>Abyss_of_Dreams</td>\n",
       "      <td>2</td>\n",
       "      <td>1.584523e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>fkmq0d</td>\n",
       "      <td>AskScienceDiscussion</td>\n",
       "      <td>2020-03-18 09:21:44</td>\n",
       "      <td>australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fktka9j</td>\n",
       "      <td>(Also, this is how those fire blankets work,)</td>\n",
       "      <td>PivotPsycho</td>\n",
       "      <td>1</td>\n",
       "      <td>1.584524e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>fkmq0d</td>\n",
       "      <td>AskScienceDiscussion</td>\n",
       "      <td>2020-03-18 09:28:41</td>\n",
       "      <td>australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fkghpja</td>\n",
       "      <td>(No where near close to the speed of light. It...</td>\n",
       "      <td>thenumber1326</td>\n",
       "      <td>7</td>\n",
       "      <td>1.584160e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>fic5q9</td>\n",
       "      <td>AskScienceDiscussion</td>\n",
       "      <td>2020-03-14 04:28:09</td>\n",
       "      <td>australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fkgqsh5</td>\n",
       "      <td>(120 meters per second,)</td>\n",
       "      <td>sunceramics</td>\n",
       "      <td>3</td>\n",
       "      <td>1.584170e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>fic5q9</td>\n",
       "      <td>AskScienceDiscussion</td>\n",
       "      <td>2020-03-14 07:12:01</td>\n",
       "      <td>australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fkof6et</td>\n",
       "      <td>(Almost like you could find this answer in a m...</td>\n",
       "      <td>pickles1486</td>\n",
       "      <td>1</td>\n",
       "      <td>1.584386e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>fic5q9</td>\n",
       "      <td>AskScienceDiscussion</td>\n",
       "      <td>2020-03-16 19:13:15</td>\n",
       "      <td>australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2175</th>\n",
       "      <td>g2p3p37</td>\n",
       "      <td>(I said global warming started, not C02 levels...</td>\n",
       "      <td>sennasappel</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.598281e+09</td>\n",
       "      <td>9</td>\n",
       "      <td>g2oztqo</td>\n",
       "      <td>climateskeptics</td>\n",
       "      <td>2020-08-24 14:59:06</td>\n",
       "      <td>california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2176</th>\n",
       "      <td>g2pj4fw</td>\n",
       "      <td>(Just in the last decade the C02 levels have r...</td>\n",
       "      <td>sennasappel</td>\n",
       "      <td>1</td>\n",
       "      <td>1.598289e+09</td>\n",
       "      <td>9</td>\n",
       "      <td>g2phvjl</td>\n",
       "      <td>climateskeptics</td>\n",
       "      <td>2020-08-24 17:03:07</td>\n",
       "      <td>california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2177</th>\n",
       "      <td>g2oyzhi</td>\n",
       "      <td>(Ah so we're dumb and dishonest. Gotcha.,)</td>\n",
       "      <td>smilodoner</td>\n",
       "      <td>3</td>\n",
       "      <td>1.598279e+09</td>\n",
       "      <td>9</td>\n",
       "      <td>g2oxv3d</td>\n",
       "      <td>climateskeptics</td>\n",
       "      <td>2020-08-24 14:18:49</td>\n",
       "      <td>california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178</th>\n",
       "      <td>g2lk1ue</td>\n",
       "      <td>(an opinion piece by the MANN himself, I thoug...</td>\n",
       "      <td>sobakablack</td>\n",
       "      <td>1</td>\n",
       "      <td>1.598200e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>ieptn4</td>\n",
       "      <td>climateskeptics</td>\n",
       "      <td>2020-08-23 16:27:39</td>\n",
       "      <td>california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2179</th>\n",
       "      <td>g2llhmt</td>\n",
       "      <td>(Yes, although it's relevant right now due to ...</td>\n",
       "      <td>SftwEngr</td>\n",
       "      <td>1</td>\n",
       "      <td>1.598201e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>g2lk1ue</td>\n",
       "      <td>climateskeptics</td>\n",
       "      <td>2020-08-23 16:40:16</td>\n",
       "      <td>california</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3321 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               body  \\\n",
       "0     fktjz0a  (Yep.   You could do this experiment now.   Li...   \n",
       "1     fktka9j      (Also, this is how those fire blankets work,)   \n",
       "2     fkghpja  (No where near close to the speed of light. It...   \n",
       "3     fkgqsh5                           (120 meters per second,)   \n",
       "4     fkof6et  (Almost like you could find this answer in a m...   \n",
       "...       ...                                                ...   \n",
       "2175  g2p3p37  (I said global warming started, not C02 levels...   \n",
       "2176  g2pj4fw  (Just in the last decade the C02 levels have r...   \n",
       "2177  g2oyzhi         (Ah so we're dumb and dishonest. Gotcha.,)   \n",
       "2178  g2lk1ue  (an opinion piece by the MANN himself, I thoug...   \n",
       "2179  g2llhmt  (Yes, although it's relevant right now due to ...   \n",
       "\n",
       "           authorname  ups   created_utc  depth parent_id  \\\n",
       "0     Abyss_of_Dreams    2  1.584523e+09      0    fkmq0d   \n",
       "1         PivotPsycho    1  1.584524e+09      0    fkmq0d   \n",
       "2       thenumber1326    7  1.584160e+09      0    fic5q9   \n",
       "3         sunceramics    3  1.584170e+09      0    fic5q9   \n",
       "4         pickles1486    1  1.584386e+09      0    fic5q9   \n",
       "...               ...  ...           ...    ...       ...   \n",
       "2175      sennasappel   -1  1.598281e+09      9   g2oztqo   \n",
       "2176      sennasappel    1  1.598289e+09      9   g2phvjl   \n",
       "2177       smilodoner    3  1.598279e+09      9   g2oxv3d   \n",
       "2178      sobakablack    1  1.598200e+09      0    ieptn4   \n",
       "2179         SftwEngr    1  1.598201e+09      1   g2lk1ue   \n",
       "\n",
       "                 subreddit                date        wave  \n",
       "0     AskScienceDiscussion 2020-03-18 09:21:44   australia  \n",
       "1     AskScienceDiscussion 2020-03-18 09:28:41   australia  \n",
       "2     AskScienceDiscussion 2020-03-14 04:28:09   australia  \n",
       "3     AskScienceDiscussion 2020-03-14 07:12:01   australia  \n",
       "4     AskScienceDiscussion 2020-03-16 19:13:15   australia  \n",
       "...                    ...                 ...         ...  \n",
       "2175       climateskeptics 2020-08-24 14:59:06  california  \n",
       "2176       climateskeptics 2020-08-24 17:03:07  california  \n",
       "2177       climateskeptics 2020-08-24 14:18:49  california  \n",
       "2178       climateskeptics 2020-08-23 16:27:39  california  \n",
       "2179       climateskeptics 2020-08-23 16:40:16  california  \n",
       "\n",
       "[3321 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('reddit_df.pickle', 'rb') as handle:\n",
    "    reddit_df = pickle.load(handle)\n",
    "    \n",
    "display(reddit_df)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Climatechange Australia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.read_gexf(\"climatechange_aus.gexf\")\n",
    "    \n",
    "threads = pd.Series([g.subgraph(c) for c in nx.weakly_connected_component_subgraphs(g)])\n",
    "    \n",
    "subreddit_threads = []\n",
    "all_trigger_subs_df = []\n",
    "    \n",
    "for c,g in enumerate(threads):\n",
    "    \n",
    "    comment_branch = list(nx.dag_longest_path(g))\n",
    "    lpcb_df = reddit_df[reddit_df[\"id\"].isin(comment_branch)]\n",
    "    temp_sorted = lpcb_df.sort_values(\"depth\",ascending=True)    \n",
    "    \n",
    "    count = 0\n",
    "    for index,row in temp_sorted.iterrows():\n",
    "        if count < 1:\n",
    "            c = row.parent_id                         \n",
    "            subreddit_threads.append(c)\n",
    "            count += 1\n",
    "            \n",
    "    # Run another API call to get trigger submissions    \n",
    "    \n",
    "    subs = {}    \n",
    "        \n",
    "    for cs in subreddit_threads:\n",
    "        s = reddit.submission(id = '{}'.format(cs))\n",
    "        subs[cs] = (s.id, s.title, s.author, s.ups, s.num_comments)    \n",
    "        cs_df = pd.DataFrame(subs, index=[\"id\",\"title\",\"author\",\"ups_sub\", \"n_comments_sub\"]).T\n",
    "        all_trigger_subs_df.append(cs_df)\n",
    "\n",
    "all_trigger_subs_df = pd.concat(all_trigger_subs_df) \n",
    "\n",
    "display(all_trigger_subs_df)\n",
    "\n",
    "# Store data (serialize)\n",
    "with open('trigger_climatechange_aus.pickle', 'wb') as handle:\n",
    "    pickle.dump(all_trigger_subs_df, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# write to csv\n",
    "all_trigger_subs_df.to_csv(r'trigger_climatechange_aus.csv', index = True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Climateskeptics Australia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>ups_sub</th>\n",
       "      <th>n_comments_sub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fgbpgq</th>\n",
       "      <td>fgbpgq</td>\n",
       "      <td>CSIRO Bushfire Fact Sheet Makes Claims Not Sup...</td>\n",
       "      <td>Prophetica2020</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fgbpgq</th>\n",
       "      <td>fgbpgq</td>\n",
       "      <td>CSIRO Bushfire Fact Sheet Makes Claims Not Sup...</td>\n",
       "      <td>Prophetica2020</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fgbpgq</th>\n",
       "      <td>fgbpgq</td>\n",
       "      <td>CSIRO Bushfire Fact Sheet Makes Claims Not Sup...</td>\n",
       "      <td>Prophetica2020</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fg0s99</th>\n",
       "      <td>fg0s99</td>\n",
       "      <td>Coal mine fire in Pennsylvania, burning since ...</td>\n",
       "      <td>None</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fgbpgq</th>\n",
       "      <td>fgbpgq</td>\n",
       "      <td>CSIRO Bushfire Fact Sheet Makes Claims Not Sup...</td>\n",
       "      <td>Prophetica2020</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f4qpxx</th>\n",
       "      <td>f4qpxx</td>\n",
       "      <td>Wildfire Smoke Boosts Photosynthetic Efficiency</td>\n",
       "      <td>sobakablack</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f4s0ow</th>\n",
       "      <td>f4s0ow</td>\n",
       "      <td>What Were the Australian Bushfires Really Abou...</td>\n",
       "      <td>clemaneuverers</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f2pat8</th>\n",
       "      <td>f2pat8</td>\n",
       "      <td>Au: ABC has 'shifted' from 'fire to flood alar...</td>\n",
       "      <td>Kim147</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f16zv5</th>\n",
       "      <td>f16zv5</td>\n",
       "      <td>As predicted , the rain puts the fires out and...</td>\n",
       "      <td>ox-</td>\n",
       "      <td>54</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f11u47</th>\n",
       "      <td>f11u47</td>\n",
       "      <td>The Arctic is on fire.</td>\n",
       "      <td>Prophetica2020</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6467 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                              title  \\\n",
       "fgbpgq  fgbpgq  CSIRO Bushfire Fact Sheet Makes Claims Not Sup...   \n",
       "fgbpgq  fgbpgq  CSIRO Bushfire Fact Sheet Makes Claims Not Sup...   \n",
       "fgbpgq  fgbpgq  CSIRO Bushfire Fact Sheet Makes Claims Not Sup...   \n",
       "fg0s99  fg0s99  Coal mine fire in Pennsylvania, burning since ...   \n",
       "fgbpgq  fgbpgq  CSIRO Bushfire Fact Sheet Makes Claims Not Sup...   \n",
       "...        ...                                                ...   \n",
       "f4qpxx  f4qpxx    Wildfire Smoke Boosts Photosynthetic Efficiency   \n",
       "f4s0ow  f4s0ow  What Were the Australian Bushfires Really Abou...   \n",
       "f2pat8  f2pat8  Au: ABC has 'shifted' from 'fire to flood alar...   \n",
       "f16zv5  f16zv5  As predicted , the rain puts the fires out and...   \n",
       "f11u47  f11u47                             The Arctic is on fire.   \n",
       "\n",
       "                author ups_sub n_comments_sub  \n",
       "fgbpgq  Prophetica2020       6              7  \n",
       "fgbpgq  Prophetica2020       4              7  \n",
       "fgbpgq  Prophetica2020       4              7  \n",
       "fg0s99            None      15              2  \n",
       "fgbpgq  Prophetica2020       5              7  \n",
       "...                ...     ...            ...  \n",
       "f4qpxx     sobakablack      22              2  \n",
       "f4s0ow  clemaneuverers      15              2  \n",
       "f2pat8          Kim147       6              2  \n",
       "f16zv5             ox-      54              8  \n",
       "f11u47  Prophetica2020      26             12  \n",
       "\n",
       "[6467 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = nx.read_gexf(\"climateskeptics_aus.gexf\")\n",
    "    \n",
    "threads = pd.Series([g.subgraph(c) for c in nx.weakly_connected_component_subgraphs(g)])\n",
    "    \n",
    "subreddit_threads = []\n",
    "all_trigger_subs_df = []\n",
    "    \n",
    "for c,g in enumerate(threads):\n",
    "    \n",
    "    comment_branch = list(nx.dag_longest_path(g))\n",
    "    lpcb_df = reddit_df[reddit_df[\"id\"].isin(comment_branch)]\n",
    "    temp_sorted = lpcb_df.sort_values(\"depth\",ascending=True)    \n",
    "    \n",
    "    count = 0\n",
    "    for index,row in temp_sorted.iterrows():\n",
    "        if count < 1:\n",
    "            c = row.parent_id                         \n",
    "            subreddit_threads.append(c)\n",
    "            count += 1\n",
    "            \n",
    "    # Run another API call to get trigger submissions    \n",
    "    \n",
    "    subs = {}    \n",
    "        \n",
    "    for cs in subreddit_threads:\n",
    "        s = reddit.submission(id = '{}'.format(cs))\n",
    "        subs[cs] = (s.id, s.title, s.author, s.ups, s.num_comments)    \n",
    "        cs_df = pd.DataFrame(subs, index=[\"id\",\"title\",\"author\",\"ups_sub\", \"n_comments_sub\"]).T\n",
    "        all_trigger_subs_df.append(cs_df)\n",
    "\n",
    "all_trigger_subs_df = pd.concat(all_trigger_subs_df) \n",
    "\n",
    "display(all_trigger_subs_df)\n",
    "\n",
    "# Store data (serialize)\n",
    "with open('trigger_climateskeptics_aus.pickle', 'wb') as handle:\n",
    "    pickle.dump(all_trigger_subs_df, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# write to csv\n",
    "all_trigger_subs_df.to_csv(r'trigger_climateskeptics_aus.csv', index = True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Climatechange California"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>ups_sub</th>\n",
       "      <th>n_comments_sub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>jg8jxp</th>\n",
       "      <td>jg8jxp</td>\n",
       "      <td>The current Northern Colorado wildfires are ap...</td>\n",
       "      <td>camawa</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jg8jxp</th>\n",
       "      <td>jg8jxp</td>\n",
       "      <td>The current Northern Colorado wildfires are ap...</td>\n",
       "      <td>camawa</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jg8jxp</th>\n",
       "      <td>jg8jxp</td>\n",
       "      <td>The current Northern Colorado wildfires are ap...</td>\n",
       "      <td>camawa</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jbvwpn</th>\n",
       "      <td>jbvwpn</td>\n",
       "      <td>A tiny pest helped stoke this yearâs devasta...</td>\n",
       "      <td>Independent_Goose551</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jg8jxp</th>\n",
       "      <td>jg8jxp</td>\n",
       "      <td>The current Northern Colorado wildfires are ap...</td>\n",
       "      <td>camawa</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ip27re</th>\n",
       "      <td>ip27re</td>\n",
       "      <td>They Know How to Prevent Megafires. Why Won’t ...</td>\n",
       "      <td>kernals12</td>\n",
       "      <td>83</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ihii3g</th>\n",
       "      <td>ihii3g</td>\n",
       "      <td>Controlled Burns Can Reduce Wildfires says Sta...</td>\n",
       "      <td>kernals12</td>\n",
       "      <td>71</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ig9arj</th>\n",
       "      <td>ig9arj</td>\n",
       "      <td>Yes, climate change is almost certainly fuelin...</td>\n",
       "      <td>_062862</td>\n",
       "      <td>114</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>if3win</th>\n",
       "      <td>if3win</td>\n",
       "      <td>Why the Apparent decline in wildfires up to th...</td>\n",
       "      <td>kernals12</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hjsuaq</th>\n",
       "      <td>hjsuaq</td>\n",
       "      <td>One wild chart shows intensity of this year’s ...</td>\n",
       "      <td>Newman1651</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24246 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                              title  \\\n",
       "jg8jxp  jg8jxp  The current Northern Colorado wildfires are ap...   \n",
       "jg8jxp  jg8jxp  The current Northern Colorado wildfires are ap...   \n",
       "jg8jxp  jg8jxp  The current Northern Colorado wildfires are ap...   \n",
       "jbvwpn  jbvwpn  A tiny pest helped stoke this yearâs devasta...   \n",
       "jg8jxp  jg8jxp  The current Northern Colorado wildfires are ap...   \n",
       "...        ...                                                ...   \n",
       "ip27re  ip27re  They Know How to Prevent Megafires. Why Won’t ...   \n",
       "ihii3g  ihii3g  Controlled Burns Can Reduce Wildfires says Sta...   \n",
       "ig9arj  ig9arj  Yes, climate change is almost certainly fuelin...   \n",
       "if3win  if3win  Why the Apparent decline in wildfires up to th...   \n",
       "hjsuaq  hjsuaq  One wild chart shows intensity of this year’s ...   \n",
       "\n",
       "                      author ups_sub n_comments_sub  \n",
       "jg8jxp                camawa       1              1  \n",
       "jg8jxp                camawa       1              1  \n",
       "jg8jxp                camawa       1              1  \n",
       "jbvwpn  Independent_Goose551       8              1  \n",
       "jg8jxp                camawa       1              1  \n",
       "...                      ...     ...            ...  \n",
       "ip27re             kernals12      83             18  \n",
       "ihii3g             kernals12      71             22  \n",
       "ig9arj               _062862     114             14  \n",
       "if3win             kernals12      34              5  \n",
       "hjsuaq            Newman1651       5              1  \n",
       "\n",
       "[24246 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = nx.read_gexf(\"climatechange_cal.gexf\")\n",
    "    \n",
    "threads = pd.Series([g.subgraph(c) for c in nx.weakly_connected_component_subgraphs(g)])\n",
    "    \n",
    "subreddit_threads = []\n",
    "all_trigger_subs_df = []\n",
    "    \n",
    "for c,g in enumerate(threads):\n",
    "    \n",
    "    comment_branch = list(nx.dag_longest_path(g))\n",
    "    lpcb_df = reddit_df[reddit_df[\"id\"].isin(comment_branch)]\n",
    "    temp_sorted = lpcb_df.sort_values(\"depth\",ascending=True)    \n",
    "    \n",
    "    count = 0\n",
    "    for index,row in temp_sorted.iterrows():\n",
    "        if count < 1:\n",
    "            c = row.parent_id                         \n",
    "            subreddit_threads.append(c)\n",
    "            count += 1\n",
    "            \n",
    "    # Run another API call to get trigger submissions    \n",
    "    \n",
    "    subs = {}    \n",
    "        \n",
    "    for cs in subreddit_threads:\n",
    "        s = reddit.submission(id = '{}'.format(cs))\n",
    "        subs[cs] = (s.id, s.title, s.author, s.ups, s.num_comments)    \n",
    "        cs_df = pd.DataFrame(subs, index=[\"id\",\"title\",\"author\",\"ups_sub\", \"n_comments_sub\"]).T\n",
    "        all_trigger_subs_df.append(cs_df)\n",
    "\n",
    "all_trigger_subs_df = pd.concat(all_trigger_subs_df) \n",
    "\n",
    "display(all_trigger_subs_df)\n",
    "\n",
    "# Store data (serialize)\n",
    "with open('trigger_climatechange_cal.pickle', 'wb') as handle:\n",
    "    pickle.dump(all_trigger_subs_df, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# write to csv\n",
    "all_trigger_subs_df.to_csv(r'trigger_climatechange_cal.csv', index = True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Climateskeptics California"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>ups_sub</th>\n",
       "      <th>n_comments_sub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>jdrl47</th>\n",
       "      <td>jdrl47</td>\n",
       "      <td>US forest fires: NBCNews got drunk and blurted...</td>\n",
       "      <td>pr-mth-s</td>\n",
       "      <td>108</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jdrl47</th>\n",
       "      <td>jdrl47</td>\n",
       "      <td>US forest fires: NBCNews got drunk and blurted...</td>\n",
       "      <td>pr-mth-s</td>\n",
       "      <td>103</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jdrl47</th>\n",
       "      <td>jdrl47</td>\n",
       "      <td>US forest fires: NBCNews got drunk and blurted...</td>\n",
       "      <td>pr-mth-s</td>\n",
       "      <td>106</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jdrl47</th>\n",
       "      <td>jdrl47</td>\n",
       "      <td>US forest fires: NBCNews got drunk and blurted...</td>\n",
       "      <td>pr-mth-s</td>\n",
       "      <td>105</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jdrl47</th>\n",
       "      <td>jdrl47</td>\n",
       "      <td>US forest fires: NBCNews got drunk and blurted...</td>\n",
       "      <td>pr-mth-s</td>\n",
       "      <td>104</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inazd9</th>\n",
       "      <td>inazd9</td>\n",
       "      <td>Climate change causes car fires</td>\n",
       "      <td>Kim147</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ige7i8</th>\n",
       "      <td>ige7i8</td>\n",
       "      <td>NASA: Area Burned Globally By Wildfires Droppe...</td>\n",
       "      <td>-mylankovic-</td>\n",
       "      <td>94</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ig2moa</th>\n",
       "      <td>ig2moa</td>\n",
       "      <td>Climate change is worsening California's helli...</td>\n",
       "      <td>SftwEngr</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ifg7di</th>\n",
       "      <td>ifg7di</td>\n",
       "      <td>The Governor of California believes forest fir...</td>\n",
       "      <td>Long_DuckDonger</td>\n",
       "      <td>215</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ieptn4</th>\n",
       "      <td>ieptn4</td>\n",
       "      <td>Climate change is burning down California. It'...</td>\n",
       "      <td>SftwEngr</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>545575 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                              title  \\\n",
       "jdrl47  jdrl47  US forest fires: NBCNews got drunk and blurted...   \n",
       "jdrl47  jdrl47  US forest fires: NBCNews got drunk and blurted...   \n",
       "jdrl47  jdrl47  US forest fires: NBCNews got drunk and blurted...   \n",
       "jdrl47  jdrl47  US forest fires: NBCNews got drunk and blurted...   \n",
       "jdrl47  jdrl47  US forest fires: NBCNews got drunk and blurted...   \n",
       "...        ...                                                ...   \n",
       "inazd9  inazd9                    Climate change causes car fires   \n",
       "ige7i8  ige7i8  NASA: Area Burned Globally By Wildfires Droppe...   \n",
       "ig2moa  ig2moa  Climate change is worsening California's helli...   \n",
       "ifg7di  ifg7di  The Governor of California believes forest fir...   \n",
       "ieptn4  ieptn4  Climate change is burning down California. It'...   \n",
       "\n",
       "                 author ups_sub n_comments_sub  \n",
       "jdrl47         pr-mth-s     108             14  \n",
       "jdrl47         pr-mth-s     103             14  \n",
       "jdrl47         pr-mth-s     106             14  \n",
       "jdrl47         pr-mth-s     105             14  \n",
       "jdrl47         pr-mth-s     104             14  \n",
       "...                 ...     ...            ...  \n",
       "inazd9           Kim147      12              2  \n",
       "ige7i8     -mylankovic-      94              8  \n",
       "ig2moa         SftwEngr       9              3  \n",
       "ifg7di  Long_DuckDonger     215             97  \n",
       "ieptn4         SftwEngr       2              2  \n",
       "\n",
       "[545575 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = nx.read_gexf(\"climateskeptics_cal.gexf\")\n",
    "    \n",
    "threads = pd.Series([g.subgraph(c) for c in nx.weakly_connected_component_subgraphs(g)])\n",
    "    \n",
    "subreddit_threads = []\n",
    "all_trigger_subs_df = []\n",
    "    \n",
    "for c,g in enumerate(threads):\n",
    "    \n",
    "    comment_branch = list(nx.dag_longest_path(g))\n",
    "    lpcb_df = reddit_df[reddit_df[\"id\"].isin(comment_branch)]\n",
    "    temp_sorted = lpcb_df.sort_values(\"depth\",ascending=True)    \n",
    "    \n",
    "    count = 0\n",
    "    for index,row in temp_sorted.iterrows():\n",
    "        if count < 1:\n",
    "            c = row.parent_id                         \n",
    "            subreddit_threads.append(c)\n",
    "            count += 1\n",
    "            \n",
    "    # Run another API call to get trigger submissions    \n",
    "    \n",
    "    subs = {}    \n",
    "        \n",
    "    for cs in subreddit_threads:\n",
    "        s = reddit.submission(id = '{}'.format(cs))\n",
    "        subs[cs] = (s.id, s.title, s.author, s.ups, s.num_comments)    \n",
    "        cs_df = pd.DataFrame(subs, index=[\"id\",\"title\",\"author\",\"ups_sub\", \"n_comments_sub\"]).T\n",
    "        all_trigger_subs_df.append(cs_df)\n",
    "\n",
    "all_trigger_subs_df = pd.concat(all_trigger_subs_df) \n",
    "\n",
    "display(all_trigger_subs_df)\n",
    "\n",
    "# Store data (serialize)\n",
    "with open('trigger_climateskeptics_cal.pickle', 'wb') as handle:\n",
    "    pickle.dump(all_trigger_subs_df, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# write to csv\n",
    "all_trigger_subs_df.to_csv(r'trigger_climateskeptics_cal.csv', index = True, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
