getwd()
comment_data <- read.csv( "data/final/comment_data_tox.csv")
######### Automating the Analysis of Online Deliberation #############
#devtools::install_github("favstats/peRspective")
library(peRspective)
library(tidyverse)
library(readr)
library(readxl)
library(xtable)
library(knitr)
library(kableExtra)
library(stargazer)
library(writexl)
library(psych)
library(gridExtra)
library(ggcorrplot)
comment_data <- read.csv( "data/final/comment_data_preprocessed.csv")
thread_data <- read.csv("data/final/thread_data_preprocessed.csv")
# Level of analysis: Threads
# Adding alternative measures for
# 1. Argumentation (length comments)
comment_data$arg_l_coms <- nchar(comment_data$text_c)
hist(comment_data$arg_l_coms)
mean(comment_data$arg_l_coms)
# 2. Reciprocity (N comments)
comment_data$rec_n_coms <- comment_data$n_comments_sub
hist(comment_data$rec_n_coms)
mean(comment_data$rec_n_coms)
# 3. Respect (Toxicity) using Perspective API (Google)
# https://github.com/favstats/peRspective
#usethis::edit_r_environ()
# add:  perspective_api_key="AIzaSyB0dABPIS0t0GkVKJM7mZlG8n4HDmtCcs8"
#test
#prsp_score(comment_data$text_c[1], languages = "en",
#           score_model = "TOXICITY", doNotStore = TRUE)
#big run
#tox_data <- comment_data%>%
#  prsp_stream(text = text_c,
#              text_id = id_c,
#              score_model = c("TOXICITY", "SEVERE_TOXICITY"),
#              safe_output = T,
#              languages = "en",
#              doNotStore = TRUE)
#
#write_xlsx(tox_data, "data/temp/tox_data.xlsx")
tox_data <- read_excel("data/temp/tox_data.xlsx")
tox_data$id_c <- tox_data$text_id
comment_data_tox <- left_join(comment_data, tox_data, by.y = "id_c")
hist(comment_data_tox$TOXICITY)
comment_data_tox%>%
arrange(desc(TOXICITY))%>%
select(text_c)%>%
head() # pretty accurate haha
# add scores to thread data
thread_data_tox <- comment_data_tox%>%
dplyr::group_by(id_sub) %>%
mutate(TOXICITY = mean(TOXICITY),
arg_l_coms = mean(arg_l_coms),
rec_n_coms = mean(rec_n_coms))%>%
slice(1)
write.csv(comment_data_tox, file = "data/final/comment_data_tox.csv")
write.csv(thread_data_tox, file = "data/final/thread_data_tox.csv")
########### Only run extension models ###########
comment_data <- read.csv( "data/final/comment_data_tox.csv")
thread_data <- read.csv("data/final/thread_data_tox.csv")
### Try to ameliorate automated analysis
mod1 <- lm(deliberation ~ scale(max_thread_depth) + scale(gonzalez_width), data = comment_data)
mod2 <- lm(deliberation ~ scale(log(arg_l_coms)) + scale(TOXICITY) + scale(rec_n_coms), data = comment_data)
mod3 <- lm(deliberation ~ scale(max_thread_depth) + scale(gonzalez_width), data = thread_data)
mod4 <- lm(deliberation ~ scale(log(arg_l_coms)) + scale(TOXICITY) + scale(rec_n_coms), data = thread_data)
mod5 <- lm(deliberation ~ scale(max_thread_depth) + scale(gonzalez_width)+ scale(log(arg_l_coms)) + scale(TOXICITY) + scale(rec_n_coms), data = comment_data)
mod6 <- lm(deliberation ~ scale(max_thread_depth) + scale(gonzalez_width)+ scale(log(arg_l_coms)) + scale(TOXICITY) + scale(rec_n_coms), data = thread_data)
mod7 <- lm(deliberation ~ scale(max_thread_depth) + scale(gonzalez_width)+scale(log(arg_l_coms)) + scale(TOXICITY) + scale(rec_n_coms) + opposing, data = comment_data)
mod8 <- lm(deliberation ~ scale(max_thread_depth) + scale(gonzalez_width)+scale(log(arg_l_coms)) + scale(TOXICITY) + scale(rec_n_coms) + opposing, data = thread_data)
# comment level data
stargazer(mod1, mod2, mod5, mod7, type = "latex", omit = "Constant")
#thread level data
stargazer(mod3, mod4, mod6, mod8, type = "latex", omit = "Constant")
##### Correlation Plot with all qualitative and computational measures
corr_data <- comment_data%>%
dplyr::select(del_complexity_G, gonzalez_width, max_thread_depth, arg_l_coms, rec_n_coms, TOXICITY,
respect, argumentation, reciprocity, empathy, emotion, humor)%>%
mutate_all(~as.numeric(as.character(.)))%>%
plyr::rename(c("del_complexity_G" = "Structural Complexity",
"gonzalez_width" = "Thread Width",
"max_thread_depth" = "Thread Depth",
"arg_l_coms" = "Comment Length",
"rec_n_coms" = "Number of Replies",
"TOXICITY" = "Toxicity",
"respect" = "Respect",
"argumentation" = "Argumentation",
"reciprocity"  = "Reciprocity",
"empathy" = "Empathy",
"emotion" = "Emotion",
"humor" = "Humor"
))
corr <- round(cor(corr_data, use = "pairwise.complete.obs"), 1)
p.mat <- cor_pmat(corr_data, use = "pairwise.complete.obs")
corr_c_plot <- ggcorrplot(corr, method = "circle", type = "upper",
outline.col = "white",
title = "Bivariate Correlations - Comment Level Data", insig = "blank",
tl.cex = 8,
tl.srt = 90,
lab = T, lab_size = 3, show.legend = F)
corr_c_plot
ggsave("output/corr_comments_plot.pdf", width = 6, height = 5, dpi = 300, corr_c_plot)
### Scatterplot with textual measures between subreddits
# create summary score of textual measures
comment_data <- comment_data%>% # change to "thread_data" and run code below for thread level data
mutate(text_deliberation = (TOXICITY+arg_l_coms+rec_n_coms)/3,
deliberation = scale(deliberation),
text_deliberation = scale(text_deliberation),
del_complexity_G = scale(del_complexity_G))
sum <- comment_data%>%
group_by(subreddit)%>%
summarise(mean_del = mean(deliberation),
se_del = sd(deliberation)/sqrt(n()),
mean_txt = mean(text_deliberation),
se_txt = sd(text_deliberation)/sqrt(n()),
mean_str = mean(del_complexity_G),
se_str = sd(del_complexity_G)/sqrt(n()),
n = n()
)
p1 <- ggplot(comment_data, aes(x=deliberation, y=text_deliberation, colour = subreddit)) +
geom_point(alpha = 0.1)+
#geom_point(data=thread_data, alpha = 0.3, size=5)+
geom_point(data = sum, aes(x=mean_del, y=mean_txt),size = 3)+
geom_errorbarh(data = sum, aes(x=mean_del, y=mean_txt,
xmax = mean_del+se_del, xmin = mean_del-se_del))+
geom_errorbar(data = sum, aes(x=mean_del, y=mean_txt,
ymax = mean_txt+se_txt,ymin = mean_txt-se_txt))+
geom_smooth(data = comment_data, method = lm,  size = 0.5, color = "black",alpha = 0.3)+
theme_bw()+
scale_colour_manual(values = c("blue", "red"))+
labs(colour ="Subreddit Mean",
x = "Deliberative quality (content coding)",
y = "Textual features of deliberative quality")+
theme(legend.position = c(.88,.9))+
ylim(-1, 3)
p1
ggsave("output/scatter_science_text.png", width = 6, height = 5, dpi = 500, p1)
# run old plot again (using structural measures)
p2 <- ggplot(comment_data, aes(x=deliberation, y=del_complexity_G, colour = subreddit)) +
geom_point(alpha = 0.1)+
#geom_point(data=thread_data, alpha = 0.3, size=5)+
geom_point(data = sum, aes(x=mean_del, y=mean_str), size = 3)+
geom_errorbarh(data = sum, aes(x=mean_del, y=mean_str,
xmax = mean_del+se_del, xmin = mean_del-se_del))+
geom_errorbar(data = sum, aes(x=mean_del, y=mean_str,
ymax = mean_str+se_str,ymin = mean_str-se_str))+
geom_smooth(data = comment_data, method = lm,  size = 0.5, color = "black",alpha = 0.3)+
theme_bw()+
scale_colour_manual(values = c("blue", "red"))+
labs(colour ="Subreddit Mean",
x = "Deliberative quality (content coding)",
y = "Structural complexity (depth x max width)")+
theme(legend.position = c(.88,.9))+
ylim(-1, 3)
p2
ggsave("output/scatter_science_del.png", width = 6, height = 5, dpi = 500, p2)
combi <- grid.arrange(p2, p1, nrow = 1)
ggsave("output/scatter_science_combi.png", width = 12, height = 5, dpi = 500, combi)
#### descriptives for automated measures between subreddits
comment_data <- read.csv( "../data/final/comment_data_preprocessed.csv")
